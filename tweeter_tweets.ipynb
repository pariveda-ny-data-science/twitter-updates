{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import twitter\n",
    "from datetime import date, timedelta\n",
    "from config import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Twitter Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_KEYWORDS='ai%20OR%20ml%20OR%20data%20OR%20science%20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt = config(section='twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key=twt['consumer_key'],\n",
    "                  consumer_secret=twt['consumer_secret'],\n",
    "                  access_token_key=twt['access_token_key'],\n",
    "                  access_token_secret=twt['access_token_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method that strips the Twitter response and only takes fields I care about into a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editDataFrameToColumnsIWant(searchResults):\n",
    "    COLUMNS = ['id', 'created_at', 'hashtags', 'retweet_count', 'text']\n",
    "    df = pd.DataFrame.from_records(results.AsDict() for results in searchResults)\n",
    "    temp_user_data = df.user.apply(lambda user: [user.get('name'), user.get('screen_name'),user.get('followers_count')]).apply(pd.Series)\n",
    "    temp_user_data.columns = ['name','screen_name', 'followers_count']                                  \n",
    "    df = df.loc[:, COLUMNS]\n",
    "    df = pd.concat([df, temp_user_data], axis = 1)\n",
    "    df = df.astype({\"id\": str})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to take in hashtag keyword search and how many days back you want to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largeHashTagDataGrab(hashtag, daysback):\n",
    "    firstSearch = api.GetSearch(raw_query = \"q={}%23{}%20since%3A{}%20until%3A{}&src=typd&lang=en&count=100\".format(SEARCH_KEYWORDS,hashtag, date.today() - timedelta(1), date.today()))\n",
    "    largeResults = editDataFrameToColumnsIWant(firstSearch)\n",
    "    for x in range(1,daysback):\n",
    "        tempResults = api.GetSearch(raw_query = \"q={}%23{}%20since%3A{}%20until%3A{}&src=typd&lang=en&count=100\".format(SEARCH_KEYWORDS,hashtag, date.today() - timedelta(x+1), date.today() - timedelta(x)))\n",
    "        tempDF = editDataFrameToColumnsIWant(tempResults)\n",
    "        largeResults = pd.concat([largeResults, tempDF])\n",
    "    return largeResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for Azure, GCP, and AWS Tweets X days back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsAzure = largeHashTagDataGrab('azure', 3)\n",
    "resultsGCP = largeHashTagDataGrab('gcp', 3)\n",
    "resultsAWS = largeHashTagDataGrab('aws', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.isdir(\"./data_output\")):\n",
    "    os.mkdir('./data_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsAWS.to_csv('data_output/df_aws.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsAzure.to_csv('data_output/df_azure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsGCP.to_csv('data_output/df_gcp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
